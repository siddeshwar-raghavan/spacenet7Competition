{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SpaceNet 7 Data for Model Training\n",
    "\n",
    "We assume that initial steps of README have been executed and that this notebook is running in a docker container.  See the `src` directory for functions used in the algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location (edit as needed)\n",
    "root_dir = '/home/ubuntu/sn7/aws_download/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage\n",
    "import gdal\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import solaris as sol\n",
    "from solaris.raster.image import create_multiband_geotiff\n",
    "from solaris.utils.core import _check_gdf_load\n",
    "\n",
    "# import from data_prep_funcs\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from sn7_baseline_prep_funcs import map_wrapper, make_geojsons_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 aoi: L15-0331E-1257N_1327_3160_13\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-99df42c6ee21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moutput_path_mask_fbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m              \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/solaris/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "# Create Training Masks\n",
    "# Multi-thread to increase speed\n",
    "# We'll only make a 1-channel mask for now, but Solaris supports a multi-channel mask as well, see\n",
    "#     https://github.com/CosmiQ/solaris/blob/master/docs/tutorials/notebooks/api_masks_tutorial.ipynb\n",
    "\n",
    "aois = sorted([f for f in os.listdir(os.path.join(root_dir, 'train'))\n",
    "               if os.path.isdir(os.path.join(root_dir, 'train', f))])\n",
    "n_threads = 10\n",
    "params = [] \n",
    "make_fbc = True\n",
    "output_path_mask = ''\n",
    "input_args = []\n",
    "for i, aoi in enumerate(tqdm(aois)):\n",
    "    print(i, \"aoi:\", aoi)\n",
    "    im_dir = os.path.join(root_dir, 'train', aoi, 'images_masked/')\n",
    "    json_dir = os.path.join(root_dir, 'train', aoi, 'labels_match/')\n",
    "    out_dir_mask = os.path.join(root_dir, 'train', aoi, 'masks/')\n",
    "    out_dir_mask_fbc = os.path.join(root_dir, 'train', aoi, 'masks_fbc/')\n",
    "    os.makedirs(out_dir_mask, exist_ok=True)\n",
    "    if make_fbc:\n",
    "        os.makedirs(out_dir_mask_fbc, exist_ok=True)\n",
    "\n",
    "    json_files = sorted([f\n",
    "                for f in os.listdir(os.path.join(json_dir))\n",
    "                if f.endswith('Buildings.geojson') and os.path.exists(os.path.join(json_dir, f))])\n",
    "    for j, f in enumerate(tqdm(json_files)):\n",
    "        # print(i, j, f)\n",
    "        name_root = f.split('.')[0]\n",
    "        json_path = os.path.join(json_dir, f)\n",
    "        image_path = os.path.join(im_dir, name_root + '.tif').replace('labels', 'images').replace('_Buildings', '')\n",
    "        \n",
    "        if make_fbc:\n",
    "            #print('3 channel')\n",
    "            output_path_mask_fbc = os.path.join(out_dir_mask_fbc, name_root + '.tif')\n",
    "            \n",
    "        else:\n",
    "            output_path_mask = os.path.join(out_dir_mask, name_root + '.tif')\n",
    "            output_path_mask_fbc = None\n",
    "            \n",
    "        if (os.path.exists(output_path_mask)):\n",
    "             continue\n",
    "        else: \n",
    "            input_args.append([make_geojsons_and_masks, \n",
    "                               name_root, image_path, json_path,\n",
    "                               output_path_mask, output_path_mask_fbc])\n",
    "\n",
    "# execute \n",
    "print(\"len input_args\", len(input_args))\n",
    "print(\"Execute...\\n\")\n",
    "with multiprocessing.Pool(n_threads) as pool:\n",
    "    pool.map(map_wrapper, input_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect visually\n",
    "\n",
    "aoi = 'L15-0331E-1257N_1327_3160_13'\n",
    "im_dir = os.path.join(root_dir, 'train', aoi, 'images_masked')\n",
    "mask_dir = os.path.join(root_dir, 'train', aoi, 'masks')\n",
    "\n",
    "im_list = sorted([z for z in os.listdir(im_dir) if z.endswith('.tif')])\n",
    "im_file = im_list[0]\n",
    "\n",
    "im_path = os.path.join(im_dir, im_file)\n",
    "mask_path = os.path.join(mask_dir, im_file.split('.')[0] + '_Buildings.tif')\n",
    "im = skimage.io.imread(im_path)\n",
    "mask = skimage.io.imread(mask_path)\n",
    "\n",
    "figsize=(24, 12)\n",
    "name = im_file.split('.')[0].split('global_monthly_')[-1]\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=figsize)\n",
    "_ = ax0.imshow(im)\n",
    "ax0.set_xticks([])\n",
    "ax0.set_yticks([])\n",
    "# _ = ax0.set_title(name)\n",
    "_ = ax1.imshow(mask)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "# _ = ax1.set_title(name)\n",
    "_ = fig.suptitle(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make identifier plots\n",
    "\n",
    "aoi = 'L15-0331E-1257N_1327_3160_13'\n",
    "im_dir = os.path.join(root_dir, 'train', aoi, 'images_masked')\n",
    "json_dir = os.path.join(root_dir, 'train', aoi, 'labels_match/')\n",
    "\n",
    "# colors\n",
    "vmax = 200\n",
    "cmap = plt.get_cmap('hsv')  # 'jet'\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=vmax)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "plot_only_first_and_last = True\n",
    "label_font_size = 4\n",
    "im_pix_size_x, im_pix_size_y = 1024, 1024\n",
    "figsize=(20,20)\n",
    "\n",
    "json_files = sorted([f\n",
    "            for f in os.listdir(json_dir)\n",
    "            if f.endswith('Buildings.geojson') and os.path.exists(os.path.join(json_dir, f))])\n",
    "if plot_only_first_and_last:\n",
    "    json_files = [json_files[0], json_files[-1]]\n",
    "\n",
    "# convert json\n",
    "for j, f in enumerate(json_files):\n",
    "    # print(i, j, f)\n",
    "    name_root = f.split('.')[0]\n",
    "    json_path = os.path.join(json_dir, f)\n",
    "    image_path = os.path.join(im_dir, name_root + '.tif').replace('_Buildings', '')\n",
    "    print(\"name_root:\", name_root)\n",
    "    # print(\"json_path\", json_path)\n",
    "    # output_path = os.path.join(out_dir, f)\n",
    "    # if os.path.exists(output_path):\n",
    "    #    print(\"  path exists, skipping:\", name_root)\n",
    "    #    continue\n",
    "    gdf_pix = sol.vector.polygon.geojson_to_px_gdf(json_path, image_path, geom_col='geometry', precision=None,\n",
    "                  output_path=None, override_crs=False)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for _, row in gdf_pix.iterrows():\n",
    "        geom = row['geometry']\n",
    "        poly_id = row['Id']\n",
    "        x, y = geom.exterior.xy\n",
    "        cx, cy = np.array(geom.centroid.xy).astype(float)\n",
    "        #print(\"centroid:\", centroid)\n",
    "        color_int = int(poly_id) % vmax\n",
    "        colorVal = scalarMap.to_rgba(color_int)\n",
    "        ax.plot(x, y, c=colorVal)\n",
    "        # poly id\n",
    "        ax.annotate(str(poly_id), xy=(cx, cy), ha='center', size=label_font_size)\n",
    "        #text_object = plt.annotate(label, xy=(x_values[i], y_values[i]), ha='center')\n",
    "        #ax.text(cx, cy, str(poly_id))\n",
    "    ax.set_xlim(0, im_pix_size_x)\n",
    "    ax.set_ylim(0, im_pix_size_y)\n",
    "    title = str(j) + \" - \" + name_root + \" - N buildings = \" + str(len(gdf_pix))\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe csvs for train/test\n",
    "\n",
    "out_dir = os.path.join(root_dir, 'csvs/')\n",
    "pops = ['train', 'test_public']\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for pop in pops: \n",
    "    d = os.path.join(root_dir, pop)\n",
    "    outpath = os.path.join(out_dir, 'sn7_baseline_' + pop + '_df.csv')\n",
    "    im_list, mask_list = [], []\n",
    "    subdirs = sorted([f for f in os.listdir(d) if os.path.isdir(os.path.join(d, f))])\n",
    "    for subdir in subdirs:\n",
    "        \n",
    "        if pop == 'train':\n",
    "            if make_fbc:\n",
    "                im_files = [os.path.join(d, subdir, 'images_masked', f)\n",
    "                        for f in sorted(os.listdir(os.path.join(d, subdir, 'images_masked')))\n",
    "                        if f.endswith('.tif') and os.path.exists(os.path.join(d, subdir, 'masks_fbc', f.split('.')[0] + '_Buildings.tif'))]\n",
    "                mask_files = [os.path.join(d, subdir, 'masks_fbc', f.split('.')[0] + '_Buildings.tif')\n",
    "                          for f in sorted(os.listdir(os.path.join(d, subdir, 'images_masked')))\n",
    "                          if f.endswith('.tif') and os.path.exists(os.path.join(d, subdir, 'masks_fbc', f.split('.')[0] + '_Buildings.tif'))]\n",
    "                im_list.extend(im_files)\n",
    "                mask_list.extend(mask_files)\n",
    "            else:\n",
    "                im_files = [os.path.join(d, subdir, 'images_masked', f)\n",
    "                        for f in sorted(os.listdir(os.path.join(d, subdir, 'images_masked')))\n",
    "                        if f.endswith('.tif') and os.path.exists(os.path.join(d, subdir, 'masks', f.split('.')[0] + '_Buildings.tif'))]\n",
    "                mask_files = [os.path.join(d, subdir, 'masks', f.split('.')[0] + '_Buildings.tif')\n",
    "                          for f in sorted(os.listdir(os.path.join(d, subdir, 'images_masked')))\n",
    "                          if f.endswith('.tif') and os.path.exists(os.path.join(d, subdir, 'masks', f.split('.')[0] + '_Buildings.tif'))]\n",
    "                im_list.extend(im_files)\n",
    "                mask_list.extend(mask_files)\n",
    "    \n",
    "        elif pop == 'test_public':\n",
    "            im_files = [os.path.join(d, subdir, 'images_masked', f)\n",
    "                    for f in sorted(os.listdir(os.path.join(d, subdir, 'images_masked')))\n",
    "                    if f.endswith('.tif')]\n",
    "            im_list.extend(im_files)\n",
    "\n",
    "    # save to dataframes\n",
    "    # print(\"im_list:\", im_list)\n",
    "    # print(\"mask_list:\", mask_list)\n",
    "    if pop == 'train':\n",
    "        df = pd.DataFrame({'image': im_list, 'label': mask_list})\n",
    "        display(df.head())\n",
    "    elif pop == 'test_public':\n",
    "        df = pd.DataFrame({'image': im_list})\n",
    "    df.to_csv(outpath, index=False)\n",
    "    print(pop, \"len df:\", len(df))\n",
    "    print(\"output csv:\", outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "We are now ready to proceed with training and testing, see sn7_baseline.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
